\section{数据同步}
数据同步：当数据源发生改变时，其他相关数据也跟着发展变化。根据需求不同可采取以下方案。
\begin{itemize}
\item 触发器：在数据库建立增删改的触发器。触发器将变更放到一张临时表里。其优点在于：实时同步，缺点：影响到业务系统，因为需要在业务系统建立触发器。
\item 日志：通过分析源数据库日志，来获得源数据库中的变化的数据。优点：不影响业务系统，缺点：有一定延时，对于没有提供日志分析接口的数据源，开发的难度比较大。对商品这类的表，数据量比较大（有无用于描述商品入库时间的属性列，如果有，就有了时间戳信息），而且很可能没有时间戳。
\par \qquad 目前对于业务数据库实时同步到数据仓库中，最简单的方案是给业务数据库增加一个从(Slave)数据库，从数据库一般通过读取主数据库的OpLog（记录了每一次数据变化的操作），来和主(Master)数据库来保持数据的一致性，并且不会对主数据库造成很大的性能影响。最简单的，我们可以通过每分钟对从数据库的新增数据进行一次扫描读取，来传输到数据仓库中，因为业务系统是不连接从数据库的，所以这不会对业务系统造成影响。既然读取主数据库的OpLog便可以在不大影响性能的情况下保持数据的准实时同步，那么我们为什么还需要一个从数据库呢？这确实是解决问题的一个思路，不过解析OpLog相对于直接SQL查询从数据库来说更加困难，开发成本较高。腾讯的TDBank数据仓库系统中，采用了类似的方案，他们开发了MyDbSync软件，通过解析MySQL的binlog（也就是OpLog）来同步数据，取得了良好的使用效果。 
\item 时间戳：在要同步的源表里有时间戳字段，每当数据发生变化，时间戳会记录发生变化的时间，设置一个限制，只提取最近一段时间以来添加的数据。Sqoop是Hadoop生态圈的工具，支持渐进式的，将关系数据库内容导入到hdfs，或将hdfs数据导入到关系数据库中，提供了基于某个列的时间戳或ID大小，来导入最近添加（修改）的行到hdfs中。商场数据库中，对于用户的一次购买活动，描述这个购买活动记录的应该有时间戳信息，可以用这个信息，来同步与用户购买活动相关的表。
\item 数据比较：通过比较两边数据源数据，来完成数据同步。一般用于实时性要求不高的场景。假如一张表有几十万条记录，每次同步都要比较全部的行，比较麻烦。但是，如果商场数据库中,用来描述商场本身信息的表肯定很小，可以采取这种方式。
\item 全表拷贝：定时清空目的数据源，将源数据源的数据全盘拷贝到目的数据源。一般用于数据量不大，实时性要求不高的场景。
这种方式，看不出价值在哪里。
\end{itemize}
\par 上面五种数据同步方式，除了第五种都需要业务表有主键。对于没有触发器和日志的一些小型数据源，如txt文本，excel文件，Aceess，则只能使用后三种方式。对于大型数据源，一般优先选择日志方式，如\textbf{ORCALE Asynchronized CDC},对于不能通过日志来实现的情况，可以考虑第1，3，4种方式。
\section{数据仓库}
\par \textbf{数据仓库是：面向主题的、集成的、稳定的、面向时间的数据集合。}一句简单的话，阐述了数据仓库系统的至少一半以上的任务。面向主题的、集成的、稳定的、面向时间的，这四个形容词中，最好理解的，便是面向时间的。以民航部门拥有的出行信息为例，每一天出行的旅客、目的地等信息都是不同的，这样的记录的时间性，在航空公司的业务数据库中，可能仅仅是每条记录中的一个记录时间（年月日时分秒或者其它的什么形式）的字段，但是在数据仓库中，则是不然。数据仓库中，时间是一切数据的分类的第一方法。所有的类别、来源的数据，若是在一个时间段内产生（通常以天或周为单位），都会用相同的方法做分类。分类的方式可能是表，也可能是Hive等系统中某表中的一个分区，显然目前后者是更加常用的。所以，数据仓库中往往拥有业务数据库中的数据在时间周期内的变化的全部历史。例如我国全部航班的总的起飞数量这一数据，在业务数据库中，很可能只存储了最新的数据，但是在数据仓库中，由于每日（或周或小时）都将业务数据库的数据装入数据仓库的一个周期分类中，所以，总是能够查找到每个时间周期的全部历史数据。
\par 稳定这个特性，则指的是数据仓库中的数据，一旦从数据源中存入，便不会再进行任何变化（也就是说，是只读的，而数据库总是存储最新的满足一致性的某个历史版本），只会在此基础上进行进一步的分析处理。
\par 集成这个特性也是很好理解的，在业务数据库系统中，不同的业务系统往往使用不同类型和位置的数据库，但是在数据仓库系统中，无论何种数据源，无论是access、sql server、Mysql还是Oracle，甚至是系统访问日志，都会被统一装入同一个数据仓库系统，这便是数据仓库系统的集成性了。这里，我们把装入数据仓库系统之前数据所在的位置叫做数据源，数据源可以是异构的，也就是说可以是任何形态存储的，甚至是人工录入的。
\par 数据仓库的四个特性中，“面向主题的”是比较难以理解的。很难用一两句定义来解释其中主题二字的含义。那么我们便只能以一个例子来说明：还是以航空公司为例，在航空公司的业务数据库中，更受关注的往往是你乘坐的航班的编号、你选用的航空公司、你登机的时间等等，在用户通过数据库查询时，被查询最多的，也便是这些信息。但是在数据仓库中，这些信息的重要性往往不如作为主体的用户更加重要。航空公司们往往希望通过挖掘每个用户的行为特征，来更加精准的为客户提供服务和推送广告，这里，围绕客户的信息便是一个主题。
\par 数据仓库的数据分为三个层面来叙述：数据运营层(ODS)、数据仓库层(DW)和数据产品层（Product）。数据运营层，也叫ODS层，是最接近数据源中数据的一层，数据源中的数据，经过抽取、洗净、传输，也就说传说中的ETL之后，装入本层。本层的数据，总体上大多是按照源头业务系统的分类方式而分类的。例如这一层可能包含的数据表为：客户表（包含每个客户的身份证号、姓名、住址等）、机场登机记录（包含乘机人身份证号、航班号、乘机日期、起飞城市等）、银联的刷卡信息表（包含银行卡号、刷卡地点、刷卡时间、刷卡金额等）、银行账户表（包含银行卡号、持卡人身份证号等）等等一系列原始的业务数据。这里我们可以看到，这一层面的数据还具有鲜明的业务数据库的特征，甚至还具有一定的关系数据库中的数据范式的组织形式。但是，这一层面的数据却不等同于原始数据。在源数据装入这一层时，要进行诸如去噪（例如去掉明显偏离正常水平的银行刷卡信息）、去重（例如银行账户信息、公安局人口信息中均含有人的姓名，但是只保留一份即可）、提脏（例如有的人的银行卡被盗刷，在十分钟内同时有两笔分别在中国和日本的刷卡信息，这便是脏数据）、业务提取、单位统一、消减属性（例如用于支撑前端系统工作，但是在数据挖掘中不需要的属性字段）、业务判别等多项工作。
\par 数据仓库层\textbf{(DW)}，是数据仓库的主体，在这里，从ODS层中获得的数据按照主题建立各种数据模型。例如以研究人的旅游消费为主题的数据集中，便可以结合航空公司的登机出行信息，以及银联系统的刷卡记录，进行结合分析，产生数据集。在这里，需要了解四个概念：维\textbf{(Dimension)}）、事实\textbf{(Fact)}和粒度\textbf{(Granularity)}。
\par 事实\textbf{(Fact)}数据是一切数据的基础，是针对某一特定事件的度量。以上一段中研究人的旅游消费为主题的数据集为例，这个数据集中的主体的事实数据，便是人在出行到目的地之后，在目的地城市的刷卡消费信息，这一数据由业务发生的事实产生，所以叫做事实数据。维\textbf{(Dimension)}则是事实数据的其中一个侧面，例如人的旅行的目的地，则便是旅行消费信息的一个维度。
\par 在淘宝网（天猫）中，以交易为主题建立一个数据集，那么每一笔交易的信息便构成一个事实表，每一个交易可能有几十个维度，例如商品的类目、卖家、买家、品牌等等。将全部的商品类目提取出来构成一张表，那么这张表便是这个数据集的一个维度表。在大型数据仓库中，维度表往往非常复杂。例如在淘宝（天猫）中，仅类目一个维度，便包含八十余个一级类目（行业类目）、成千上万个二，三，四级类目、以及最底层的叶子类目等信息，各个类目之间还存在着树状的关联，有的一级类目便同时是叶子类目（例如手机类目）。这些维度信息构成了庞大的围绕着事实数据的维度表系统。
\par 粒度\textbf{(Granularity)}则表示数据仓库中数据集的精细程度。粒度越高，则数据的细节越多。例如在高粒度的数据表中，会包含一个人在任何城市中的每一条的刷卡记录，而在低粒度表中，则可能只包含一个人在各个城市中的刷卡总金额。这便是粒度不同的体现。这么做，是因为大多数的分析挖掘往往仅关注低维度的数据集合，那么使用高维度的数据集进行输入便会大规模的浪费系统资源。
\par 在数据仓库层中，数据按照主题组织，按照不同的事实、维度进行组合和关联分析，构成了数据仓库中主体的数据。而最后一层数据产品层，则是数据仓库中的最上层。数据产品层使用数据仓库层的数据集，针对要输出的产品不同，而进行不同的数据开发组合。例如一个分析每个城市的旅游人员的刷卡金额的数据产品，则可以在这一层中，按照城市维度，进行各大银行刷卡信息汇总的数据计算。
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "weka"
%%% End: 
